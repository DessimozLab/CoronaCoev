{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "         \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import csb\n",
    "import pandas as pd \n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "from colour import Color\n",
    "import pickle\n",
    "\n",
    "import h5py\n",
    "import dendropy\n",
    "from Bio import AlignIO , SeqIO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B1', 'N_bar', '__class__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_as_newick_string', '_assign_node_labels_from_taxon', '_bipartition_edge_map', '_clone_from', '_compile_immutable_bipartition_for_edge', '_compile_mutable_bipartition_for_edge', '_debug_check_tree', '_debug_tree_is_valid', '_del_taxon_namespace', '_del_taxon_set', '_format_and_write_to_stream', '_get_annotations', '_get_bipartition_edge_map', '_get_from', '_get_indented_form', '_get_is_rooted', '_get_is_rootedness_undefined', '_get_is_unrooted', '_get_label', '_get_seed_node', '_get_split_bitmask_edge_map', '_get_split_edges', '_get_taxon_namespace', '_get_taxon_set', '_has_annotations', '_is_rooted', '_label', '_parse_and_create_from_stream', '_plot_bipartitions_on_tree', '_print_newick', '_seed_node', '_set_annotations', '_set_is_rooted', '_set_is_unrooted', '_set_label', '_set_seed_node', '_set_split_edges', '_set_taxon_namespace', '_set_taxon_set', '_split_bitmask_edge_map', '_taxon_namespace', '_write_indented_form', '_write_newick', '_write_to', 'age_order_node_iter', 'ageorder_node_iter', 'annotations', 'apply', 'as_ascii_plot', 'as_python_source', 'as_string', 'automigrate_taxon_namespace_on_assignment', 'bipartition_edge_map', 'bipartition_encoding', 'calc_node_ages', 'calc_node_root_distances', 'clone', 'coalescence_intervals', 'collapse_basal_bifurcation', 'collapse_unweighted_edges', 'colless_tree_imbalance', 'comments', 'copy_annotations_from', 'deep_copy_annotations_from', 'delete_outdegree_one_nodes', 'deroot', 'description', 'edges', 'encode_bipartitions', 'encode_splits', 'error', 'euclidean_distance', 'extract_tree', 'extract_tree_with_taxa', 'extract_tree_with_taxa_labels', 'extract_tree_without_taxa', 'extract_tree_without_taxa_labels', 'false_positives_and_negatives', 'filter_leaf_nodes', 'find_missing_splits', 'find_node', 'find_node_for_taxon', 'find_node_with_label', 'find_node_with_taxon', 'find_node_with_taxon_label', 'find_nodes', 'from_bipartition_encoding', 'from_split_bitmasks', 'get', 'get_from_path', 'get_from_stream', 'get_from_string', 'get_from_url', 'has_annotations', 'infer_taxa', 'inorder_edge_iter', 'inorder_node_iter', 'internal_edges', 'internal_node_ages', 'internal_nodes', 'is_compatible_with_bipartition', 'is_compatible_with_tree', 'is_rooted', 'is_rootedness_undefined', 'is_unrooted', 'label', 'ladderize', 'leaf_edge_iter', 'leaf_edges', 'leaf_iter', 'leaf_node_iter', 'leaf_nodes', 'length', 'length_type', 'level_order_edge_iter', 'level_order_node_iter', 'levelorder_edge_iter', 'levelorder_node_iter', 'max_distance_from_root', 'migrate_taxon_namespace', 'minmax_leaf_distance_from_root', 'mrca', 'node_ages', 'node_distance_matrix', 'node_factory', 'nodes', 'num_lineages_at', 'phylogenetic_distance_matrix', 'poll_taxa', 'postorder_edge_iter', 'postorder_internal_edge_iter', 'postorder_internal_node_iter', 'postorder_node_iter', 'preorder_edge_iter', 'preorder_internal_edge_iter', 'preorder_internal_node_iter', 'preorder_node_iter', 'print_plot', 'prune_leaves_without_taxa', 'prune_nodes', 'prune_subtree', 'prune_taxa', 'prune_taxa_with_labels', 'purge_taxon_namespace', 'pybus_harvey_gamma', 'randomly_assign_taxa', 'randomly_reorient', 'randomly_rotate', 'read', 'read_from_path', 'read_from_stream', 'read_from_string', 'read_from_url', 'reconstruct_taxon_namespace', 'reindex_subcomponent_taxa', 'reindex_taxa', 'reroot_at_edge', 'reroot_at_midpoint', 'reroot_at_node', 'reseed_at', 'resolve_polytomies', 'retain_taxa', 'retain_taxa_with_labels', 'robinson_foulds_distance', 'rooting_state_is_undefined', 'sackin_index', 'scale_edges', 'seed_node', 'set_edge_lengths_from_node_ages', 'shuffle_taxa', 'split_bitmask_edge_map', 'split_edges', 'strip_comments', 'suppress_unifurcations', 'symmetric_difference', 'taxon_namespace', 'taxon_namespace_scoped_copy', 'taxon_set', 'to_outgroup_position', 'treeness', 'truncate_from_root', 'unassign_taxa', 'update_bipartitions', 'update_splits', 'update_taxon_namespace', 'weight', 'write', 'write_as_dot', 'write_ascii_plot', 'write_to_path', 'write_to_stream', 'yield_from_files']\n"
     ]
    }
   ],
   "source": [
    "tree = dendropy.Tree.get(\n",
    "    path='./lanford/ft_TBE.tree.txt',\n",
    "    schema='newick')\n",
    "print(dir(tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hCoV-19/Wuhan/WH04/2020|EPI ISL 406801|2020-01-05'\n",
      "'hCoV-19/Xinyu/JX122/2020|EPI ISL 421249|2020-01-25'\n",
      "'hCoV-19/Guangzhou/GZMU0046/2020|EPI ISL 429093|2020-02-08'\n",
      "'hCoV-19/Wuhan/WHUH011/2020|EPI ISL 449484|2020-01-22'\n",
      "'hCoV-19/Sichuan/SC-WCH3-255/2020|EPI ISL 451384|2020-01-27'\n",
      "'hCoV-19/Guangzhou/GZMU0048/2020|EPI ISL 414691|2020-02-25'\n",
      "'hCoV-19/Nanchang/JXN3T4/2020|EPI ISL 421246|2020-02-26'\n",
      "'hCoV-19/Guangzhou/GZMU0078/2020|EPI ISL 457690|2020-02-11'\n",
      "'hCoV-19/Ganzhou/JX81/2020|EPI ISL 421242|2020-01-25'\n",
      "'hCoV-19/Shangrao/JX29/2020|EPI ISL 421244|2020-01-22'\n",
      "36257\n",
      "leaves\n",
      "72513\n",
      "nodes\n"
     ]
    }
   ],
   "source": [
    "for l in tree.leaf_nodes()[0:10]:\n",
    "    print(str(l.taxon))\n",
    "print(len(tree.leaf_nodes()))\n",
    "print('leaves')\n",
    "for i,n in enumerate(tree.nodes()):\n",
    "    n.matrow = i\n",
    "    n.symbols = None\n",
    "    n.scores = None\n",
    "    n.event = None\n",
    "    n.char = None\n",
    "\n",
    "    \n",
    "matsize = len(tree.nodes())\n",
    "print(matsize)\n",
    "print('nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: hCoV-19/Wuhan/WIV04/2019|EPI_ISL_402124|2019-12-30|China\n",
      "Name: hCoV-19/Wuhan/WIV04/2019|EPI_ISL_402124|2019-12-30|China\n",
      "Description: hCoV-19/Wuhan/WIV04/2019|EPI_ISL_402124|2019-12-30|China\n",
      "Number of features: 0\n",
      "Seq('------------------------------------------------------...---', SingleLetterAlphabet())\n",
      "45950\n",
      "ID: hCoV-19/USA/NY-NYUMC389/2020|EPI_ISL_430416|2020-04-13|NorthAmerica\n",
      "Name: hCoV-19/USA/NY-NYUMC389/2020|EPI_ISL_430416|2020-04-13|NorthAmerica\n",
      "Description: hCoV-19/USA/NY-NYUMC389/2020|EPI_ISL_430416|2020-04-13|NorthAmerica\n",
      "Number of features: 0\n",
      "Seq('------------------------------------------------------...---', SingleLetterAlphabet())\n",
      "45950\n",
      "ID: hCoV-19/Poland/PL_P27/2020|EPI_ISL_455440|2020-03-27|Europe\n",
      "Name: hCoV-19/Poland/PL_P27/2020|EPI_ISL_455440|2020-03-27|Europe\n",
      "Description: hCoV-19/Poland/PL_P27/2020|EPI_ISL_455440|2020-03-27|Europe\n",
      "Number of features: 0\n",
      "Seq('------------------------------------------------------...---', SingleLetterAlphabet())\n",
      "45950\n",
      "ID: hCoV-19/Scotland/EDB5128/2020|EPI_ISL_456977|2020-05-17|Europe\n",
      "Name: hCoV-19/Scotland/EDB5128/2020|EPI_ISL_456977|2020-05-17|Europe\n",
      "Description: hCoV-19/Scotland/EDB5128/2020|EPI_ISL_456977|2020-05-17|Europe\n",
      "Number of features: 0\n",
      "Seq('------------------------------------------------------...---', SingleLetterAlphabet())\n",
      "45950\n",
      "ID: hCoV-19/England/NOTT-10E696/2020|EPI_ISL_425577|2020-03-24|Europe\n",
      "Name: hCoV-19/England/NOTT-10E696/2020|EPI_ISL_425577|2020-03-24|Europe\n",
      "Description: hCoV-19/England/NOTT-10E696/2020|EPI_ISL_425577|2020-03-24|Europe\n",
      "Number of features: 0\n",
      "Seq('------------------------------------------------------...---', SingleLetterAlphabet())\n",
      "45950\n",
      "ID: hCoV-19/England/CAMB-1AEBF3/2020|EPI_ISL_448060|2020-05-04|Europe\n",
      "Name: hCoV-19/England/CAMB-1AEBF3/2020|EPI_ISL_448060|2020-05-04|Europe\n",
      "Description: hCoV-19/England/CAMB-1AEBF3/2020|EPI_ISL_448060|2020-05-04|Europe\n",
      "Number of features: 0\n",
      "Seq('------------------------------------------------------...---', SingleLetterAlphabet())\n",
      "45950\n",
      "ID: hCoV-19/Australia/VIC1619/2020|EPI_ISL_456527|2020-05-08|Oceania\n",
      "Name: hCoV-19/Australia/VIC1619/2020|EPI_ISL_456527|2020-05-08|Oceania\n",
      "Description: hCoV-19/Australia/VIC1619/2020|EPI_ISL_456527|2020-05-08|Oceania\n",
      "Number of features: 0\n",
      "Seq('------------------------------------------------------...---', SingleLetterAlphabet())\n",
      "45950\n",
      "ID: hCoV-19/Spain/COV001368/2020|EPI_ISL_452533|2020-03-12|Europe\n",
      "Name: hCoV-19/Spain/COV001368/2020|EPI_ISL_452533|2020-03-12|Europe\n",
      "Description: hCoV-19/Spain/COV001368/2020|EPI_ISL_452533|2020-03-12|Europe\n",
      "Number of features: 0\n",
      "Seq('------------------------------------------------------...---', SingleLetterAlphabet())\n",
      "45950\n",
      "ID: hCoV-19/USA/UT-0495/2020|EPI_ISL_430048|2020-04-02|NorthAmerica\n",
      "Name: hCoV-19/USA/UT-0495/2020|EPI_ISL_430048|2020-04-02|NorthAmerica\n",
      "Description: hCoV-19/USA/UT-0495/2020|EPI_ISL_430048|2020-04-02|NorthAmerica\n",
      "Number of features: 0\n",
      "Seq('------------------------------------------------------...---', SingleLetterAlphabet())\n",
      "45950\n",
      "ID: hCoV-19/USA/WA-S395/2020|EPI_ISL_434155|2020-03-30|NorthAmerica\n",
      "Name: hCoV-19/USA/WA-S395/2020|EPI_ISL_434155|2020-03-30|NorthAmerica\n",
      "Description: hCoV-19/USA/WA-S395/2020|EPI_ISL_434155|2020-03-30|NorthAmerica\n",
      "Number of features: 0\n",
      "Seq('------------------------------------------------------...---', SingleLetterAlphabet())\n",
      "45950\n",
      "ID: hCoV-19/Northern\n",
      "Name: hCoV-19/Northern\n",
      "Description: hCoV-19/Northern Ireland/NIRE-FC7B7/2020|EPI_ISL_459378|2020-04-22|Europe\n",
      "Number of features: 0\n",
      "Seq('------------------------------------------------------...---', SingleLetterAlphabet())\n",
      "45950\n",
      "ID: hCoV-19/Scotland/EDB033/2020|EPI_ISL_425839|2020-03-13|Europe\n",
      "Name: hCoV-19/Scotland/EDB033/2020|EPI_ISL_425839|2020-03-13|Europe\n",
      "Description: hCoV-19/Scotland/EDB033/2020|EPI_ISL_425839|2020-03-13|Europe\n",
      "Number of features: 0\n",
      "Seq('------------------------------------------------------...---', SingleLetterAlphabet())\n",
      "45950\n"
     ]
    }
   ],
   "source": [
    "msa = SeqIO.parse('./gisaid/msa_0612.fasta' , format = 'fasta')\n",
    "for i,s in enumerate(msa):\n",
    "    print(s)\n",
    "    print(len(s))\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39423\n",
      "sequences filtered to\n",
      "39424\n"
     ]
    }
   ],
   "source": [
    "correctlen = 45950\n",
    "count = 0\n",
    "with open('./gisaid/msa_0612.lenfilter.fasta'  , 'w') as fastout:\n",
    "    for i,s in enumerate(msa):\n",
    "        if len(s) == correctlen:\n",
    "            count +=1\n",
    "            SeqIO.write(s, fastout , 'fasta')\n",
    "print(i)\n",
    "print('sequences filtered to')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingleLetterAlphabet() alignment with 39424 rows and 45950 columns\n",
      "--------------------------------------------...--- hCoV-19/France/50008KC/2020|EPI_ISL_447673|2020-03-00|Europe\n",
      "--------------------------------------------...--- hCoV-19/USA/MA-MGH-00701/2020|EPI_ISL_460358|2020-04-06|NorthAmerica\n",
      "--------------------------------------------...--- hCoV-19/Scotland/EDB1105/2020|EPI_ISL_433396|2020-04-08|Europe\n",
      "--------------------------------------------...--- hCoV-19/Sichuan/SC-PHCC1-030/2020|EPI_ISL_451351|2020-01-27|Asia\n",
      "--------------------------------------------...--- hCoV-19/USA/WI-UW-08/2020|EPI_ISL_417202|2020-03-21|NorthAmerica\n",
      "--------------------------------------------...--- hCoV-19/France/B2343/2020|EPI_ISL_416508|2020-03-06|Europe\n",
      "--------------------------------------------...--- hCoV-19/USA/CA-CZB043/2020|EPI_ISL_429048|2020-03-25|NorthAmerica\n",
      "--------------------------------------------...--- hCoV-19/England/EXET-1361D0/2020|EPI_ISL_457209|2020-04-14|Europe\n",
      "--------------------------------------------...--- hCoV-19/Wuhan/HB-WH2-165/2020|EPI_ISL_455375|2020-02-11|Asia\n",
      "--------------------------------------------...--- hCoV-19/India/NIV-11687/2020|EPI_ISL_452197|2020-04-19|Asia\n",
      "--------------------------------------------...--- hCoV-19/England/BRIS-122869/2020|EPI_ISL_440750|2020-04-05|Europe\n",
      "--------------------------------------------...--- hCoV-19/Scotland/CVR2447/2020|EPI_ISL_438908|2020-04-14|Europe\n",
      "--------------------------------------------...--- hCoV-19/Switzerland/1000477757/2020|EPI_ISL_413021|2020-02-29|Europe\n",
      "--------------------------------------------...--- hCoV-19/USA/CT-Yale-120/2020|EPI_ISL_431084|2020-04-11|NorthAmerica\n",
      "--------------------------------------------...--- hCoV-19/ITALY/SardiniaNuoroCOV28/2020|EPI_ISL_458085|2020-04-12|Europe\n",
      "--------------------------------------------...--- hCoV-19/Italy/INMI1-N/2020|EPI_ISL_451300|2020-02-03|Europe\n",
      "--------------------------------------------...--- hCoV-19/Australia/VIC318/2020|EPI_ISL_420009|2020-03-24|Oceania\n",
      "--------------------------------------------...--- hCoV-19/Denmark/ALAB-HH-113/2020|EPI_ISL_451997|2020-03-09|Europe\n",
      "...\n",
      "--------------------------------------------...--- hCoV-19/England/CAMB-7382E/2020|EPI_ISL_425245|2020-03-31|Europe\n",
      "39424\n"
     ]
    }
   ],
   "source": [
    "msa = AlignIO.read('./gisaid/msa_0612.lenfilter.fasta' , format = 'fasta')\n",
    "print(msa)\n",
    "print(len(msa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_array = np.array([list(rec) for rec in msa], np.character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39424, 45950)\n"
     ]
    }
   ],
   "source": [
    "print(align_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save aln array as hdf5\n",
    "\n",
    "\n",
    "try:\n",
    "    with h5py.File('./gisaid/aln.h5', 'w') as hf:\n",
    "            hf.create_dataset(\"MSA2array\",  data=align_array)\n",
    "except:\n",
    "    with h5py.File('./gisaid/aln.h5', 'r+') as hf:\n",
    "            h5array = hf['MSA2array']\n",
    "            h5array = align_array\n",
    "            print(h5array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./UKdata/aln.h5', 'r') as hf:\n",
    "    align = hf['MSA2array'][:]\n",
    "print(align.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = AlignIO.read('./gisaid/msa_0612.lenfilter.fasta' , format = 'fasta')\n",
    "def clipID(ID):\n",
    "    return ''.join( [ s +'|' for s in str(ID).split('|')[:-1] ])[:-1].replace('_',' ') \n",
    "IDs = {i:clipID(rec.id) for i,rec in enumerate(msa)}\n",
    "IDindex = dict(zip( IDs.values() , IDs.keys() ) )\n",
    "print( [(t,IDindex[t]) for t in list(IDindex.keys())[0:10]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( IDindex['hCoV-19/China/WF0001/2020|EPI ISL 413691|2020-01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#sites = { col: Counter( msa[:,col] ) for col in range(len(msa[1,:])) }\n",
    "sites = {}\n",
    "with h5py.File('./UKdata/aln.h5', 'r') as hf:\n",
    "    align_array = hf['MSA2array'][:]\n",
    "    #implement w np unique could be faster\n",
    "    for col in range(align_array.shape[1]):\n",
    "        if col% 1000  == 0:\n",
    "            print(col)\n",
    "        (unique, counts) = np.unique(align_array[:,col].ravel() , return_counts=True)\n",
    "        sites.update({col:dict(zip(list(unique), list(counts)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove uniformative sites from counter\n",
    "#send the informative ones to MI analysis\n",
    "informativesites = [ s for s in sites if len(set( sites[s].keys()) -set([b'-',b'N']) ) > 2  ]\n",
    "\n",
    "print('informative columns')\n",
    "print(len(informativesites))\n",
    "\n",
    "for letter in [ b'A' , b'C' ,b'T' ,b'G' , b'N' ,b'-']:\n",
    "    print(letter)\n",
    "    lettervec = [ sites[ID][letter] if letter in sites[ID] else 0  for ID in sites  ]\n",
    "    plt.hist(lettervec , alpha = .5 , label = letter.decode() , bins = 40)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place an event on a column with multiple symbols\n",
    "allowed_symbols = { b'A', b'C', b'G' , b'T ' , b'-'}\n",
    "from time import sleep\n",
    "\n",
    "def process_node_smallpars_1(node):\n",
    "    #go from leaves up and generate character sets\n",
    "    if node.symbols is None:\n",
    "        for child in node.child_nodes():\n",
    "            if child.symbols is None:\n",
    "                process_node_smallpars_1(child)\n",
    "        symbols = set.intersection( * [ child.symbols for child in node.child_nodes( ) ] )\n",
    "        if len(symbols) == 0:\n",
    "            symbols = set.union( * [ child.symbols for child in node.child_nodes( ) ] )\n",
    "        node.symbols = symbols\n",
    "        node.scores = { }\n",
    "        for c in allowed_symbols:\n",
    "            if c not in node.symbols:\n",
    "                #add trnasition mat here if needed\n",
    "                score = min(  [ child.scores[c] for child in node.child_nodes()])+1\n",
    "            else:\n",
    "                score = min(  [ child.scores[c] for child in node.child_nodes() ] )\n",
    "            node.scores[c] = score\n",
    "        \n",
    "def process_node_smallpars_2(node):\n",
    "    #assign the most parsimonious char from children\n",
    "    if node.char is None:\n",
    "        node.char = min(node.scores, key=node.scores.get)\n",
    "        if node.parent_node:\n",
    "            if node.parent_node.char == node.char:\n",
    "                node.event = 0\n",
    "            else:\n",
    "                node.event = 1\n",
    "        else:\n",
    "            node.event = 0\n",
    "        for child in node.child_nodes():\n",
    "            if child.char is None:\n",
    "                process_node_smallpars_2(child)\n",
    "def calculate_small_parsimony( t, aln_column , row_index , verbose  = False ):           \n",
    "    missing = 0\n",
    "    #assign leaf values\n",
    "    for l in t.leaf_nodes():\n",
    "        l.event = 0\n",
    "        try:\n",
    "            char = aln_column[row_index[str(l.taxon).replace(\"'\" , '' )]]\n",
    "        except KeyError:\n",
    "            missing += 1\n",
    "            char = None\n",
    "        if char in allowed_symbols:\n",
    "            l.symbols = { char }\n",
    "        else:\n",
    "            #ambiguous leaf with N\n",
    "            l.symbols =  allowed_symbols \n",
    "        l.scores = { c:0 if c in l.symbols else 10**10 for c in allowed_symbols }\n",
    "        l.char = min(l.scores, key=l.scores.get)\n",
    "    process_node_smallpars_1(t.seed_node)\n",
    "    \n",
    "    #down\n",
    "    process_node_smallpars_2(t.seed_node)\n",
    "    if verbose == True:\n",
    "        print('done init')\n",
    "        print(missing)\n",
    "        print('missing in aln')\n",
    "        for n in t.nodes()[0:5]:\n",
    "            print(n)\n",
    "            print(n.symbols)\n",
    "            print(n.scores)\n",
    "            print(n.char)\n",
    "            print(n.event)\n",
    "    eventindex = [ n.matrow for n in t.nodes()   if n.event > 0 ]\n",
    "    if verbose == True:\n",
    "        print(eventindex)\n",
    "    events = np.zeros( (len(t.nodes()),1) )                            \n",
    "    events[eventindex] = 1\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15397\n",
      "b'GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGKGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGKGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG-GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGNGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG'\n",
      "1.467885971069336\n",
      "(array([  417,   503,   507,   540,   573,   581,   762,  3496,  4636,\n",
      "        5217,  5747,  5848,  5893,  5953,  6389,  6769,  7287,  7572,\n",
      "        7841,  7867,  7870,  8368,  8529,  8535,  8575,  8599,  8613,\n",
      "       12201, 12350, 12388, 12791, 12805, 12929, 13497, 13514, 13539,\n",
      "       13545, 13568, 13584, 15063, 15216, 15576, 15602, 15613, 15622,\n",
      "       15798, 16794, 16907, 16914, 17469, 18480, 19012, 19057, 19085,\n",
      "       19141, 19158, 19514, 20008, 20302, 20763, 21241, 21392, 21653,\n",
      "       22032, 22272, 22301, 22787, 23944, 24202, 24432, 24444, 24458,\n",
      "       24493, 24505, 24522, 24853, 25102, 25922, 26429, 26521, 26932,\n",
      "       27469, 27685, 27690, 27782, 27799, 27886, 27901, 28038, 28231,\n",
      "       28334, 29061, 29138, 31354, 31838, 31918, 32396, 32738, 33682,\n",
      "       34023, 34435, 34670, 35085, 35615, 35630, 35635, 36223, 38337,\n",
      "       38846, 39384, 39458, 39648, 40501, 41144, 42540, 45548, 47582,\n",
      "       47895, 48047, 48060, 48066, 48235, 48240, 48494, 48501, 48512,\n",
      "       48515, 48738, 49238, 53554, 53743, 54069, 55817, 56054, 56069,\n",
      "       56095, 56101, 56104, 56121, 56127, 56160, 56189, 56196, 56240,\n",
      "       56485, 57273, 57707, 58771, 61091, 63241, 63963, 64095, 65035,\n",
      "       67257, 69103, 69154, 70559, 71808, 71823, 71843, 71849, 71865,\n",
      "       71870, 71879, 71898, 71947, 71954, 72411]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "#reset tree\n",
    "import time \n",
    "for i,n in enumerate(tree.nodes()):\n",
    "    n.matrow = i\n",
    "    n.symbols = None\n",
    "    n.scores = None\n",
    "    n.event = None\n",
    "    n.char = None\n",
    "print(informativesites[2500])\n",
    "aln_column = align_array[:, informativesites[2500] ]\n",
    "print(b\"\".join(aln_column))\n",
    "t0 = time.time()\n",
    "events = calculate_small_parsimony( tree, aln_column ,  IDindex  )\n",
    "print(time.time() - t0 )\n",
    "\n",
    "print(np.nonzero(events) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init worker\n",
      "init matcreator\n",
      "(72513, 6924)\n",
      "59\n",
      "worker\n",
      "37\n",
      "worker\n",
      "35\n",
      "worker\n",
      "58\n",
      "worker\n",
      "33\n",
      "worker\n",
      "6\n",
      "worker\n",
      "34\n",
      "worker\n",
      "45\n",
      "worker\n",
      "42\n",
      "worker\n",
      "8\n",
      "worker\n",
      "44\n",
      "worker\n",
      "7\n",
      "worker\n",
      "39\n",
      "worker\n",
      "9\n",
      "worker\n",
      "11\n",
      "worker\n",
      "10\n",
      "worker\n",
      "46\n",
      "worker\n",
      "36\n",
      "worker\n",
      "25\n",
      "worker\n",
      "24\n",
      "worker\n",
      "43\n",
      "worker\n",
      "21\n",
      "worker\n",
      "57\n",
      "worker\n",
      "55\n",
      "worker\n",
      "49\n",
      "worker\n",
      "26\n",
      "worker\n",
      "13\n",
      "worker\n",
      "27\n",
      "worker\n",
      "41\n",
      "worker\n",
      "23\n",
      "worker\n",
      "54\n",
      "worker\n",
      "22\n",
      "worker\n",
      "12\n",
      "worker\n",
      "40\n",
      "worker\n",
      "31\n",
      "worker\n",
      "53\n",
      "worker\n",
      "52\n",
      "worker\n",
      "14\n",
      "worker\n",
      "47\n",
      "worker\n",
      "51\n",
      "worker\n",
      "28\n",
      "worker\n",
      "48\n",
      "worker\n",
      "38\n",
      "worker\n",
      "32\n",
      "worker\n",
      "30\n",
      "worker\n",
      "20\n",
      "worker\n",
      "19\n",
      "worker\n",
      "56\n",
      "worker\n",
      "4\n",
      "worker\n",
      "0\n",
      "worker\n",
      "16\n",
      "worker\n",
      "29\n",
      "worker\n",
      "3\n",
      "worker\n",
      "5\n",
      "worker\n",
      "15\n",
      "worker\n",
      "2\n",
      "worker\n",
      "18\n",
      "worker\n",
      "1\n",
      "worker\n",
      "50\n",
      "worker\n",
      "17\n",
      "worker\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import copy\n",
    "def process(q,retq, iolock ,tree , IDindex   ):\n",
    "    #calculate tree events\n",
    "    with iolock:\n",
    "        print('init worker')\n",
    "    count = 0 \n",
    "    while True:\n",
    "        stuff = q.get()\n",
    "        if stuff is None:\n",
    "            break\n",
    "        index,aln_column = stuff\n",
    "        \n",
    "        retq.put((index,calculate_small_parsimony( copy.deepcopy(tree) , aln_column , IDindex ) ) ) \n",
    "        if count % 1000 == 0:\n",
    "            with iolock:\n",
    "                print(index)\n",
    "                print('worker')\n",
    "        count+= 1\n",
    "    print('done')\n",
    "    \n",
    "def mat_creator(retq,matsize,iolock):\n",
    "    with iolock:\n",
    "        print('init matcreator')\n",
    "    #collect distances and create final mat\n",
    "    distmat = np.zeros( (matsize[0],matsize[1] ) )\n",
    "    count = 0\n",
    "    init = False\n",
    "    print(distmat.shape)\n",
    "    with h5py.File('./gisaid/alnEvents.h5', 'w') as hf:\n",
    "        try:\n",
    "            hf.create_dataset(\"alnEvents\",  data=distmat)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        while True:\n",
    "            r = retq.get()\n",
    "            \n",
    "            if r is not None:\n",
    "                init = True\n",
    "            \n",
    "            count+=1\n",
    "            if r is None and init == True:\n",
    "                break\n",
    "            col,events = r\n",
    "            hf['alnEvents'][:,col] = events.ravel()\n",
    "            if count == 0:\n",
    "                with iolock:\n",
    "                    print(np.nonzero(events))\n",
    "                \n",
    "            if count% 100 == 0 :\n",
    "                with iolock:\n",
    "                    print(col)\n",
    "                    hf.flush()\n",
    "    \n",
    "    print('done saver')\n",
    "def main():\n",
    "    NCORE = 60\n",
    "    \n",
    "    #reset tree\n",
    "    for i,n in enumerate(tree.nodes()):\n",
    "        n.matrow = i\n",
    "        n.symbols = None\n",
    "        n.scores = None\n",
    "        n.event = None\n",
    "        n.char = None\n",
    "    \n",
    "    #our results will be events on tree nodes for each column\n",
    "    matsize = (len(tree.nodes()),len(informativesites))\n",
    "    q = mp.Queue(maxsize=NCORE*1000)\n",
    "    retq = mp.Queue(maxsize= NCORE*100 )\n",
    "    iolock = mp.Lock()\n",
    "    \n",
    "    #start workers\n",
    "    pool = mp.Pool(NCORE, initializer=process, initargs=(q,retq, iolock ,tree , IDindex ))\n",
    "    #start saver\n",
    "    p = mp.Process(target=mat_creator, args=(retq,matsize, iolock))\n",
    "    p.start()\n",
    "    \n",
    "    for i,k in enumerate(informativesites):\n",
    "        s1 = align_array[:,k]\n",
    "        q.put( (i,s1) )         \n",
    "    for _ in range(NCORE):  # tell workers we're done\n",
    "        q.put(None)\n",
    "    #retq.put(None)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    #retq.put(None)\n",
    "    p.join()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blur w connectivity mat\n",
    "blurfactor = 10**-3\n",
    "bluriter = 4\n",
    "\n",
    "connectmat = np.zeros((len(tree.nodes()), len(tree.nodes() ) ) )\n",
    "index = [ (n.matrow, c.matrow ) for n in tree.nodes() for c in n.child_nodes()]\n",
    "connectmat[index] = blurfactor\n",
    "\n",
    "#apply blur a few times\n",
    "for i in range( bluriter):\n",
    "    for col in range(eventmat.shape[1]):\n",
    "        eventmat[:,col] = np.linalg.multi_dot(connectmat,  eventmat[:,col] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequences = { ID:Counter( msa[i,:]) for i,ID in enumerate(IDs) }\n",
    "sequences = {}\n",
    "for i in range(len(msa)):\n",
    "    sequences.update({i:Counter(msa[i,:])})\n",
    "    if i% 1000  == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./UKdata/site_seq_stats.pkl' , 'wb') as pickleout:\n",
    "    pickleout.write(pickle.dumps([sites,informativesites, IDs , sequences]) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./UKdata/site_seq_stats.pkl' , 'rb') as pickleout:\n",
    "    sites,informativesites, IDs , sequences = pickle.loads(pickleout.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find colum mutual info using compression distance\n",
    "#find interprot and intraprot interactions\n",
    "\n",
    "import itertools\n",
    "import gzip\n",
    "import multiprocessing as mp\n",
    "import lzma\n",
    "\n",
    "import time\n",
    "\n",
    "lzma_filters = my_filters = [\n",
    "    {\n",
    "      \"id\": lzma.FILTER_LZMA2, \n",
    "      \"preset\": 9 | lzma.PRESET_EXTREME, \n",
    "      \"dict_size\":len(msa[:,0]) * 40, # a big enough dictionary, but not more than needed, saves memory\n",
    "      \"lc\": 3,\n",
    "      \"lp\": 0,\n",
    "      \"pb\": 0, # assume ascii\n",
    "      \"mode\": lzma.MODE_NORMAL,\n",
    "      \"nice_len\": 273,\n",
    "      \"mf\": lzma.MF_BT4\n",
    "    }\n",
    "]\n",
    "\n",
    "def clen(s):\n",
    "    return len( lzma.compress(s, format=lzma.FORMAT_RAW, filters= lzma_filters) )\n",
    "    #return len(gzip.compress(s))\n",
    "\n",
    "def compress_dist(pargs):\n",
    "    i,j,s1,s2 = pargs\n",
    "    strings = [s1.ravel() , s2.ravel() , np.stack([s1,s2]).ravel() ]\n",
    "    ls1 , ls2 , ls1_2 = map(clen, strings)\n",
    "    \n",
    "    return  (i,j,(ls1_2 - min(ls1,ls2) )/ max( ls1,ls2 ) )\n",
    "\n",
    "\n",
    "def str2binary(s,char):\n",
    "    return np.array([ 1 if c == char else 0 for c in s ])\n",
    "\n",
    "def byteStr2str(s):\n",
    "    return b\"\".join(list(s)).decode()\n",
    "\n",
    "def binaryH(s):\n",
    "    H = 0 \n",
    "    for c in set(s):\n",
    "        p = np.sum(str2binary(s,c))/len(s)\n",
    "        H+= p*np.log(p)\n",
    "    return H\n",
    "    \n",
    "def binaryJointH(s1,s2):\n",
    "    \n",
    "    H = 0\n",
    "    for c1 in set(s1+s2):\n",
    "        for c2 in set(s1+s2):\n",
    "            v1 = str2binary(s1,c1)\n",
    "            v2 = str2binary(s2,c2)\n",
    "            \n",
    "            sumvec = np.sum(np.vstack([v1,v2]) , axis = 0)\n",
    "            pvec = np.zeros()\n",
    "            pvec[np.where( sumvec == 2)] =1\n",
    "            p = np.sum(pvec)\n",
    "            H+= p*np.log(p)\n",
    "    return H\n",
    "\n",
    "        \n",
    "\n",
    "def MI_dist(pargs):\n",
    "    #calculate explicit MI\n",
    "    \n",
    "    #Hx + Hy - HXY\n",
    "    \n",
    "    \n",
    "    i,j,s1,s2 = pargs\n",
    "    binaryH(s1) + binaryH(s2) - binaryJointH(s1,s2)\n",
    "    strings = [s1.ravel() , s2.ravel() , np.stack([s1,s2]).ravel() ]\n",
    "    \n",
    "    ls1 , ls2 , ls1_2 = map(clen, strings)\n",
    "    return  (i,j,(ls1_2 - min(ls1,ls2) )/ max( ls1,ls2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(informativesites))\n",
    "\n",
    "print(clen(align_array[:,100].ravel()))\n",
    "print(clen(align_array[:,1000].ravel()) )\n",
    "\n",
    "print(( 308 - 163) / 183 )\n",
    "both = np.stack( [align_array[:,100].ravel(), align_array[:,1000].ravel()])\n",
    "print(clen(both) )\n",
    "print(compress_dist((100,1000, align_array[:,100],  align_array[:,1000]) ))\n",
    "\n",
    "complement = { 'A':'T' , 'T':'A' , 'C':'G' , 'G':'C' }\n",
    "newstr =  ''.join([complement[c]  if c in complement else c  for c in msa[:,informativesites[3]] ])\n",
    "\n",
    "t0 = time.time()\n",
    "print( compress_dist(   ( 100, 100 , align_array[:,informativesites[3]], align_array[:,informativesites[3]] ) ) )\n",
    "print( time.time() -t0)\n",
    "#select 100 random pairs\n",
    "\n",
    "#select 100 sites and take complement\n",
    "\n",
    "\n",
    "#double hist\n",
    "\n",
    "print( len(informativesites) ** 2)\n",
    "\n",
    "print( len(informativesites) ** 2 /  2* 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def process(q,retq, iolock):\n",
    "    #calculate compression distances\n",
    "    with iolock:\n",
    "        print('init worker')\n",
    "    from time import sleep\n",
    "    while True:\n",
    "        stuff = q.get()\n",
    "        if stuff is None:\n",
    "            break\n",
    "        retq.put(compress_dist(stuff))\n",
    "    print('done')\n",
    "def mat_creator(retq,matsize,iolock):\n",
    "    with iolock:\n",
    "        print('init matcreator')\n",
    "    #collect distances and create final mat\n",
    "    calculations = (matsize**2 - matsize) / 2\n",
    "    distmat = np.zeros((matsize,matsize))\n",
    "    count = 0\n",
    "    \n",
    "    with h5py.File('./UKdata/alnMI2.h5', 'a') as hf:\n",
    "        try:\n",
    "            hf.create_dataset(\"alnMI\",  data=distmat)\n",
    "        except:\n",
    "            pass\n",
    "        while True:\n",
    "            r = retq.get()\n",
    "            count+=1\n",
    "            if r is None:\n",
    "                break\n",
    "            row,col,cdist = r\n",
    "            hf['alnMI'][row,col] = cdist\n",
    "            if count% 100000 == 0 :\n",
    "                with iolock:\n",
    "                    print(count/calculations)\n",
    "                    print((row,col))\n",
    "                    hf.flush()\n",
    "    print('done saver')\n",
    "\n",
    "startk = 0 \n",
    "startl = 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NCORE = 64\n",
    "    q = mp.Queue(maxsize=NCORE*5000)\n",
    "    retq = mp.Queue(maxsize=NCORE*5000)\n",
    "    iolock = mp.Lock()\n",
    "    pool = mp.Pool(NCORE, initializer=process, initargs=(q,retq, iolock))\n",
    "    p = mp.Process(target=mat_creator, args=(retq,len(msa[1,:]), iolock))\n",
    "    p.start()\n",
    "    for k,i in enumerate(informativesites):\n",
    "        for l,j in enumerate(informativesites):\n",
    "            if k < l and k> startk and l > startl :\n",
    "                s1 = align_array[:,i].ravel()\n",
    "                s2 = align_array[:,j].ravel()\n",
    "                q.put( (i,j,s1,s2) )         \n",
    "                if k % 100 == 0 and l %100 == 0:\n",
    "                    print((k,l))\n",
    "                    print((i,j))\n",
    "    \n",
    "    for _ in range(NCORE):  # tell workers we're done\n",
    "        q.put(None)\n",
    "    retq.put(None)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    p.join()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise a vector of zeros with length equal to the number of sites in the alignment to record the tree length for each site\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.sparse import coo_matrix\n",
    "with h5py.File('./UKdata/alnMI2.h5', 'r') as hf:\n",
    "    print( hf['alnMI'] )\n",
    "    MImat = np.array(hf['alnMI'])\n",
    "print(MImat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MImat += MImat.T\n",
    "#MImat = 1-MImat\n",
    "#sparseMI = coo_matrix(MImat)\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(MImat)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(MImat.ravel(), bins= 40)\n",
    "plt.show()\n",
    "posi = MImat[ np.where( MImat >0 ) ].ravel() \n",
    "plt.hist(posi, bins= 40)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter sequences\n",
    "#sequences with over k undefined characters can be discarded \n",
    "nvec = [ sequences[ID]['N'] if 'N' in sequences[ID] else 0  for ID in sequences  ]\n",
    "plt.hist(nvec)\n",
    "\n",
    "plt.show()\n",
    "#make a hist of normalized sequence composition percentages\n",
    "\n",
    "for letter in [ 'A' , 'C' ,'T' ,'G' , 'N' ,'-']:\n",
    "    lettervec = [ sequences[ID][letter] if letter in sequences[ID] else 0  for ID in sequences  ]\n",
    "    plt.hist(lettervec , alpha = .5 , label = letter)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sequences))\n",
    "\n",
    "legit_IDs = [ ID for ID in sequences if sequences[ID]['N'] < 5 ]\n",
    "\n",
    "print( len(legit_IDs))\n",
    "print( legit_IDs[0:10])\n",
    "#matrows = [ IDs[s] for s in legit_IDs ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick a sequence\n",
    "sele = 10\n",
    "\n",
    "print(legit_IDs[sele])\n",
    "seq = b\"\".join(list(align_array[sele,:])).decode()\n",
    "\n",
    "print(seq[0:100])\n",
    "\n",
    "cleanseq = seq.replace('-','')\n",
    "\n",
    "print(len(seq))\n",
    "print(len(cleanseq))\n",
    "#select all nongap positions\n",
    "nongap_cols = [ i for i,s in enumerate(seq) if s is not '-']\n",
    "#map each nucleotide to an aln col\n",
    "nongap_cols = { i:col for i,col in enumerate(nongap_cols) }\n",
    "\n",
    "print(len(nongap_cols))\n",
    "\n",
    "print(cleanseq[0:100]+'...')\n",
    "#fasta = '>'+legit_IDs[sele]+'\\n'+seq\n",
    "#with open( 'testgeno.fasta' ,'w')as geno_out:\n",
    "#    geno_out.write(fasta)co\n",
    "print( len(seq) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shlex\n",
    "#####run glimmer and build icm \n",
    "#####predict orfs in a viral genome\n",
    "\n",
    "def runblastx( aln , name, path , outdir, db , iterations , ncores , runName='' , SS= False  , ohhm = False , verbose = True , Z = 2000 , B = 2000 , xargs = ' -cons '):\n",
    "    \n",
    "    #blastx -query testgeno.fasta -db covid_prots -outfmt 10\n",
    "    \n",
    "    \n",
    "    if verbose == True:\n",
    "        print( [aln , name, path , outdir, db , iterations , ncores , runName] )\n",
    "    \n",
    "    outhhr= outdir+name+runName+\".hhr\"\n",
    "    args = path + ' -cpu '+ str(ncores) +' -d ' + db + ' -i ' + aln  +' -o '+ outhhr + ' -n ' + str(iterations) + ' -B '+ str(B) + ' -Z ' + str(Z) +' '+ xargs \n",
    "    if SS == True:\n",
    "         args += ' -ssm 2 -ssw .5 '\n",
    "    \n",
    "    if ohhm == True:\n",
    "        outa3m = outdir+name+runName+'.a3m'\n",
    "        args += ' -Oa3m ' + outa3m\n",
    "    else: \n",
    "        outa3m = None\n",
    "    if verbose == True:\n",
    "        print(args)\n",
    "    \n",
    "    args = shlex.split( args)\n",
    "    p = subprocess.run( args )\n",
    "    return p , [outhhr,outa3m]\n",
    "\n",
    "\n",
    "def runGlimmer( aln , name, path , outdir, db , iterations , ncores , runName='' , SS= False  , ohhm = False , verbose = True , Z = 2000 , B = 2000 , xargs = ' -cons '):\n",
    "    # glimmer3.02/bin/glimmer3 --linear -g 20 -o 50 testgeno.fasta testgeno.fasta.icm test\n",
    "\n",
    "    if verbose == True:\n",
    "        print( [aln , name, path , outdir, db , iterations , ncores , runName] )\n",
    "    \n",
    "    outhhr= outdir+name+runName+\".hhr\"\n",
    "    args = path + ' -cpu '+ str(ncores) +' -d ' + db + ' -i ' + aln  +' -o '+ outhhr + ' -n ' + str(iterations) + ' -B '+ str(B) + ' -Z ' + str(Z) +' '+ xargs \n",
    "    if SS == True:\n",
    "         args += ' -ssm 2 -ssw .5 '\n",
    "    \n",
    "    if ohhm == True:\n",
    "        outa3m = outdir+name+runName+'.a3m'\n",
    "        args += ' -Oa3m ' + outa3m\n",
    "    else: \n",
    "        outa3m = None\n",
    "    if verbose == True:\n",
    "        print(args)\n",
    "    \n",
    "    args = shlex.split( args)\n",
    "    p = subprocess.run( args )\n",
    "    return p , [outhhr,outa3m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read orf file\n",
    "from Bio import Seq\n",
    "genes = {}\n",
    "with open('./test.predict' , 'r') as predictions:\n",
    "    for l in predictions:\n",
    "        print(l)\n",
    "        if '>' in l:\n",
    "            genome = l.strip()\n",
    "        else:\n",
    "            words = l.split()\n",
    "            start = int(words[1])\n",
    "            stop = int(words[2])\n",
    "            if stop-start>100:\n",
    "                genes.update({ genome + '_' + words[0] : { 'genome': genome , 'start':start , 'stop':stop , 'RF':words[3] , 'len':stop-start ,  'score':float(words[4]) , 'seq':seq[start-1:stop-1] } } )\n",
    "genomesDF = pd.DataFrame.from_dict(genes, orient = 'index')\n",
    "#translate\n",
    "genomesDF['prot'] = genomesDF.seq.map( lambda x:str(Seq.Seq(x).translate( ) )  )\n",
    "print(genomesDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#select genomes\n",
    "#model translated prots\n",
    "print(genomesDF.prot)\n",
    "#write out the proteomes\n",
    "\n",
    "def write_fasta( genos , genodf , path='COVIDpoteomes.fasta'  ):\n",
    "    with open( path + geno , 'w' ) as fastout:\n",
    "        for geno in genos:\n",
    "            sub = genodf[ genodf.genome.is_in( geno ) ]\n",
    "            for i,r in sub.itterrows():\n",
    "                fastout.write( '>'+ i + '\\n'+ r.prot + '\\n' )\n",
    "\n",
    "def write_split_fasta( geno , genodf , path= None  ):\n",
    "    #make a folder and split up the fasta for use with hhblits\n",
    "    \n",
    "    if path is None:\n",
    "        \n",
    "        path = './' + geno+'/'\n",
    "    sub = genodf[ genodf.genome ==  geno ]\n",
    "\n",
    "    print(sub)\n",
    "    \n",
    "    for i,r in sub.iterrows():\n",
    "        name = i.replace('>','').replace('/','_')\n",
    "        print(r)\n",
    "        with open( path + name + 'singleseq.fasta', 'w' ) as fastout:\n",
    "            fastout.write( '>'+ i + '\\n'+ r.prot + '\\n' )\n",
    "\n",
    "write_split_fasta(    '>England/BRIS-121F74/2020' , genomesDF , path = './UKdata/proteome_' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show residues that contain information: sum of that matrow in the MImat\n",
    "#these are interaction hubs? \n",
    "\n",
    "#!possible masking signal, RNA interactions from geno packing\n",
    "MIsum = np.sum(MImat , axis =0 ).ravel()\n",
    "\n",
    "filtered = MIsum[MIsum>0]\n",
    "plt.plot(filtered)\n",
    "plt.title('sum of MI on informative positions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize MIsum\n",
    "#generate colors in weird pymol format for a specific sequence. this is used with the coloring script written to load this csv\n",
    "\n",
    "red = Color(\"red\")\n",
    "blue = Color(\"blue\")\n",
    "colorscale = list(red.range_to(blue, 100))\n",
    "MIsum = np.sum(MImat , axis =0 ).ravel()\n",
    "#add up positions on AA sequences, 3 to 1 codon\n",
    "MIsumSeq = MIsum[list(nongap_cols.values())]\n",
    "\n",
    "print(MIsumSeq.shape)\n",
    "for i,r in genomesDF.itterrows():\n",
    "    print(i)\n",
    "    rawvec = list(MIsumseq[r.start:r.stop])\n",
    "    codonvec = [ sum(codon)/3 for codon in rawvec[::3]]\n",
    "    plt.plot(codonvec)\n",
    "    plt.show()\n",
    "\n",
    "plt.plot(MIsumSeq)\n",
    "plt.title('sum of MI on sequence')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_evoldf['colorscale'] = sub_evoldf.val.map( lambda x : colorscale[int( x *100 )].rgb)\n",
    "sub_evoldf['rgb'] = sub_evoldf.colorscale.map( lambda x : '0x'+''.join([ '{:2.2f}'.format(round(min(val ,.99), 2 ) ).replace('.','')[1:]  for val in x ]) ) \n",
    "\n",
    "sub_evoldf = sub_evoldf.drop( 'colorscale', axis = 1)\n",
    "print(sub_evoldf.head())\n",
    "sub_evoldf.to_csv('MIcolors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import forceatlas2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import sys\n",
    "import math\n",
    "\n",
    "# Load the graph edges and compute the node positions using ForceAtlas2\n",
    "nprots = len(genomesDF)\n",
    "r0 = 1000\n",
    "r_delta = .1\n",
    "theta_delta = 2*math.pi / nprots\n",
    "rad_counter = { i:0 for i in range(nprots) }\n",
    "#node sizes proportional to the MIsum\n",
    "#ranges = { i }\n",
    "positions={}\n",
    "backbone = []\n",
    "\n",
    "for i, prot in enumerate(genomesDF.index):\n",
    "    print(prot)\n",
    "    print(genomesDF.loc[prot])\n",
    "    count = 0\n",
    "    for j,col in enumerate(range( genomesDF.loc[prot]['start'] ,  genomesDF.loc[prot]['stop'] )):\n",
    "        count+=1\n",
    "        theta = i *theta_delta\n",
    "        r = r0 + j*r_delta\n",
    "        positions[col] = np.array([ math.sin(theta)*r , math.cos(theta)*r ])\n",
    "\n",
    "# read in the distmat\n",
    "thresh = MImat\n",
    "\n",
    "thresh[thresh >= .3 ] = 0\n",
    "\n",
    "\n",
    "\n",
    "#print(indices[0:10])\n",
    "#thresh = thresh[indices,:]\n",
    "#thresh = thresh[:,indices]\n",
    "print(thresh.shape)\n",
    "G = nx.from_numpy_matrix(thresh)\n",
    "print('done making graph')\n",
    "print(len(G.edges()))\n",
    "print(len(positions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done graph creation')\n",
    "\n",
    "nodelist = list(G.nodes())\n",
    "\n",
    "for node in nodelist:\n",
    "    if node not in positions:\n",
    "        G.remove_node(node)\n",
    "\n",
    "print(len(G.nodes()))\n",
    "print(len(positions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(G.edges(data=True)):\n",
    "    if i < 10:\n",
    "        print(e)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('done nodes')\n",
    "#add the backbone and MI connection with straight and curved\n",
    "postuples = [ [ positions[e[0]] , positions[e[1]] ] for e in G.edges(data= True)   if e[0] in positions and e[1] in positions ]\n",
    "print(len(postuples))\n",
    "\n",
    "print('done tuples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False\n",
    "plt.figure(figsize=(20,20))\n",
    "nx.draw_networkx_nodes(G, positions, node_size=5 )\n",
    "ax = plt.gca()\n",
    "for i,tup in enumerate(postuples):\n",
    "    if i %10 == 0 :\n",
    "        \n",
    "        x1,y1 = tup[0]\n",
    "        x2,y2 = tup[1]\n",
    "\n",
    "        ax.annotate(\"\",\n",
    "                    xy=(x1, y1), xycoords='data',\n",
    "                    xytext=(x2, y2), textcoords='data',\n",
    "                    arrowprops=dict(arrowstyle=\"->\", color=\"0.5\", alpha = .05 ,\n",
    "                                    shrinkA=5, shrinkB=5,\n",
    "                                    patchA=None, patchB=None,\n",
    "                                    connectionstyle=\"arc3,rad=0.3\",\n",
    "                                    ),\n",
    "                    )\n",
    "    #add protnames\n",
    "for i, prot in enumerate(genomesDF.index):\n",
    "    \n",
    "    theta = i *theta_delta\n",
    "    r = r0 + (genomesDF.loc[prot]['stop']-genomesDF.loc[prot]['start']) *r_delta + 100\n",
    "    ax.annotate( prot , (r*math.sin(theta) , r*math.cos(theta)) )\n",
    "print('plotting')\n",
    "plt.show()\n",
    "#visualize the interaction map of the proteome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shlex\n",
    "\n",
    "def runHHblits( aln , name, path , outdir, db , iterations , ncores , runName='' , SS= False  , ohhm = False , verbose = True , Z = 2000 , B = 2000 , xargs = ' -cons '):\n",
    "    if verbose == True:\n",
    "        print( [aln , name, path , outdir, db , iterations , ncores , runName] )\n",
    "    outhhr= outdir+name+runName+\".hhr\"\n",
    "    args = path + ' -cpu '+ str(ncores) +' -d ' + db + ' -i ' + aln  +' -o '+ outhhr + ' -n ' + str(iterations) + ' -B '+ str(B) + ' -Z ' + str(Z) +' '+ xargs \n",
    "    if SS == True:\n",
    "         args += ' -ssm 2 -ssw .5 '\n",
    "    \n",
    "    if ohhm == True:\n",
    "        outa3m = outdir+name+runName+'.a3m'\n",
    "        args += ' -Oa3m ' + outa3m\n",
    "    else: \n",
    "        outa3m = None\n",
    "    if verbose == True:\n",
    "        print(args)\n",
    "    args = shlex.split( args)\n",
    "    p = subprocess.run( args )\n",
    "    return p , [outhhr,outa3m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "prots = glob.glob('./UKdata/proteome*singleseq.fasta')\n",
    "print(prots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run hhblits\n",
    "results = {}\n",
    "for prot in prots:    \n",
    "    p, outfiles = runHHblits( prot , prot+'.hhr' , 'hhblits', outdir = './' , db ='/home/cactuskid13/mntpt/HHBLITsdb/pdb70/pdb70' , ohhm = True,  iterations = 1 , ncores = 8 , )\n",
    "    results[prot]=outfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse results\n",
    "from csb.bio.io.hhpred import HHOutputParser\n",
    "predDfs  = {}\n",
    "topk = 3\n",
    "models = []\n",
    "predictions = glob.glob( './UKdata/*single*.hhr')\n",
    "for pred in predictions:\n",
    "    results = HHOutputParser(alignments=False).parse_file(pred)\n",
    "    newhits = {}\n",
    "    hitlist=[]\n",
    "    for hit in results:\n",
    "        hitlist.append(hit.id)\n",
    "        newhits.update( {  hit.id : { 'prob':hit.probability, 'len' : hit.length , 'score': hit.score   , 'start':hit.start , 'stop':hit.end }}  )\n",
    "\n",
    "    hhdf = pd.DataFrame.from_dict(newhits, orient = 'index')\n",
    "    hhdf['model'] = hhdf.index.map(lambda x : x.split('_')[0])\n",
    "    hhdf['chain'] = hhdf.index.map(lambda x : x.split('_')[1])\n",
    "    print(hhdf.head())\n",
    "    predDfs[pred] = hhdf\n",
    "    models+=list(hhdf.model)[0:topk]\n",
    "print(models)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skbio import TabularMSA, Protein\n",
    "\n",
    "from Bio.Alphabet.IUPAC import protein as alpha\n",
    "\n",
    "\n",
    "alpha = list(alpha.letters)+['-'] \n",
    "print(alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have some long high quality hits to some chains\n",
    "#get templates\n",
    "import wget\n",
    "import glob\n",
    "\n",
    "dl_url = 'http://files.rcsb.org/download/'\n",
    "structs = {}\n",
    "already = glob.glob( './templates/*.pdb' )\n",
    "for m in models:\n",
    "    print(m)\n",
    "    structfile = './templates/'+m.upper()+'.pdb'\n",
    "    structs[m]= structfile\n",
    "    if structfile not in already:\n",
    "        wget.download(url = dl_url + m +'.pdb' , out =structfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "#find ca string for each strucutre\n",
    "#make sure you grab the right chain\n",
    "from Bio import Alphabet\n",
    "parser = PDBParser()\n",
    "from Bio.SeqUtils import seq1\n",
    "letter3 = Alphabet.ThreeLetterProtein.letters\n",
    "converter = { l.upper(): seq1(l) for l in letter3} \n",
    "print(converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "ali_input = {}\n",
    "builder = Polypeptide.PPBuilder()\n",
    "#slice structures in hhr\n",
    "\n",
    "io=PDBIO()\n",
    "sliceprots = False\n",
    "\n",
    "\n",
    "class resselect(Select):\n",
    "    def __init__(self, reslist):\n",
    "        self.reslist=reslist\n",
    "    \n",
    "    def accept_residue(self ,residue ):\n",
    "        if residue in self.reslist:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0      \n",
    "for df in predDfs:\n",
    "    print(predDfs[df])\n",
    "    count = 0\n",
    "    for i,row in predDfs[df].iterrows():\n",
    "        if count < topk:\n",
    "            count+=1\n",
    "            code = row.model\n",
    "            if code in structs:\n",
    "                print(code)\n",
    "\n",
    "                structure = parser.get_structure(code,structs[code])\n",
    "                io.set_structure(structure)\n",
    "\n",
    "                for chain in structure.get_chains():\n",
    "                    if chain.id == row.chain:\n",
    "                        #trim the structures to hhblits detected regions\n",
    "                        if sliceprots == True:\n",
    "                            #Dice.extract(structure=structure , chain_id=chain.id , start=row.start-1, end=row.stop , filename='./modellercif/'+row.model+'.pdb' )\n",
    "                            #sub_structure = parser.get_structure(code , './modellercif/'+row.model+'.pdb' )\n",
    "                            #subchains = [ c for c in structure.get_chains()]\n",
    "                            peptides  = [p for p in  builder.build_peptides(chain)]\n",
    "                            peptidelen  = [len(p) for p in  builder.build_peptides(chain)]\n",
    "                            print(peptidelen)\n",
    "\n",
    "                        else:\n",
    "                            #Dice.extract(structure=structure , chain_id=chain.id , start=0, end=len(chain), filename='./modellercif/'+row.model+'.pdb' )\n",
    "\n",
    "                            #sub_structure = parser.get_structure(code , './modellercif/'+row.model+'.pdb' )\n",
    "                            #sub_structure = structure\n",
    "                            peptides  = [p for p in  builder.build_peptides(chain)]\n",
    "                            peptidelen  = [len(p) for p in  builder.build_peptides(chain)]\n",
    "                            print(peptidelen)\n",
    "                            #pp = peptides[0]\n",
    "\n",
    "                        for i,pp in enumerate( peptides):\n",
    "                            #break all subchains into files\n",
    "                            if peptidelen[i] > 75:\n",
    "                                io.save('./modellercif/'+row.model+'_'+str(i) +'.pdb', resselect(pp))\n",
    "                                seq = str(pp.get_sequence())\n",
    "                                print(seq)\n",
    "                                models[row.model+'_'+str(i)]={'mdl': './modellercif/'+row.model+'_'+str(i) +'.pdb' , 'chain':chain.id }\n",
    "                            #ali_input[row.model] = { 'chain': subchains[0].id , 'seq': seq , 'start':'' , 'stop':''  } \n",
    "                        #mdl = model(env, file='./modellercif/'+row.model+'.pdb', model_segment=('FIRST:'+chain.id, 'LAST:'+chain.id))\n",
    "                        #chains = mdl.make_chains(file='./modellercif/'+row.model+'.pdb')\n",
    "\n",
    "                        #for i,pp in enumerate(peptides):\n",
    "                        #    if i > 0:\n",
    "                        #        seq+='-'\n",
    "                        #    seq += str(pp.get_sequence())\n",
    "                        #ali_input[row.model] = { 'chain': subchains[0].id , 'seq': seq , 'start':'' , 'stop':''  }     \n",
    "                        # grab all sequences from the query input\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeller import *\n",
    "import modeller.salign\n",
    "log.none()\n",
    "env = environ()\n",
    "env.io.atom_files_directory = ['./modellercif/']\n",
    "knowns = {}\n",
    "structalns = {}\n",
    "\n",
    "#aln = alignment(env, file='align2d_in.ali', align_codes='all' )\n",
    "print(models)\n",
    "for df in predDfs:\n",
    "    print(predDfs[df])\n",
    "    count = 0\n",
    "    knowns[df]=[]\n",
    "    for i,row in predDfs[df].iterrows():\n",
    "        if count < topk:\n",
    "            count +=1\n",
    "            model_list = list(predDfs[df].model)[0:topk]\n",
    "            aln = alignment(env)\n",
    "            \n",
    "            for m in models:\n",
    "                if m.split('_')[0] in model_list:\n",
    "                    print(m)\n",
    "                    mdl = model(env, file=m, model_segment=('FIRST:'+models[m]['chain'], 'LAST:'+models[m]['chain']))\n",
    "                    aln.append_model(mdl, atom_files=m, align_codes= m)\n",
    "                    knowns[df].append(m)\n",
    "            print(aln)\n",
    "            try:\n",
    "                for (weights, write_fit, whole) in (((1., 0., 0., 0., 1., 0.), False, True),\n",
    "                                            ((1., 0.5, 1., 1., 1., 0.), False, True),\n",
    "                                            ((1., 1., 1., 1., 1., 0.), True, False)):\n",
    "                    aln.salign(rms_cutoff=3.5, normalize_pp_scores=False,\n",
    "                       rr_file='$(LIB)/as1.sim.mat', overhang=30,\n",
    "                       gap_penalties_1d=(-450, -50),\n",
    "                       gap_penalties_3d=(0, 3), gap_gap_score=0, gap_residue_score=0,\n",
    "                       dendrogram_file='1is3A.tree',\n",
    "                       alignment_type='tree',\n",
    "                       feature_weights=weights, # For a multiple sequence alignment only\n",
    "                       improve_alignment=True, fit=True, write_fit=write_fit,\n",
    "                       write_whole_pdb=whole, output='ALIGNMENT QUALITY')\n",
    "                    #aln.write(file='1is3A-it.pap', alignment_format='PAP')\n",
    "                    structalns[df] = df+'.ali'\n",
    "                    aln.write(file= structalns[df], alignment_format='PIR')\n",
    "            except:\n",
    "                print('alnerr')\n",
    "            print('DONE')\n",
    "print(knowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockct = 0\n",
    "print('making sequence pir')\n",
    "\n",
    "from Bio import SeqIO\n",
    "print(predDfs.keys())\n",
    "finalaln = {}\n",
    "alidfs = {}\n",
    "#write out each seq as a gapless pir\n",
    "for df in predDfs:\n",
    "    fasta = df.replace('.hhr', '')\n",
    "    print(fasta)\n",
    "    ali_input ={}\n",
    "    for seq in SeqIO.parse(fasta , 'fasta'):\n",
    "        ali_input[seq.id] = { 'chain': '', 'seq': str(seq.seq) , 'start':1 , 'stop':len(seq.seq)  } \n",
    "    alidf = pd.DataFrame.from_dict( ali_input , orient = 'index')\n",
    "    print(alidf.head())\n",
    "    \n",
    "    \n",
    "    alidfs[df]=alidf\n",
    "    \n",
    "    \n",
    "    with open( fasta+'.ali' , 'w') as alnout:\n",
    "        for idx,row in alidf.iterrows():\n",
    "            print(row)\n",
    "            if len(row.chain ) > 0:\n",
    "                pass\n",
    "            #    line2 = 'structureX:'+idx+':'+str(row.start)+' :'+row.chain + ':' + str( row.stop  )  + ':::::'+'\\n'\n",
    "            else:\n",
    "                blockct+=1\n",
    "                print(idx)\n",
    "                line1 = '>P1;'+idx.replace('/','_') +'\\n'\n",
    "                line2 = 'sequence:'+idx+':1 : :'+str( len(row.seq) )  + ':::::' +'\\n' \n",
    "                line3 = row.seq +'*\\n'\n",
    "                #print(  line1 + line2 + line3)\n",
    "                alnout.write( line1 + line2 + line3)\n",
    "\n",
    "    print('aln struct block to seq block ')   \n",
    "    #structure sensitive aln\n",
    "\n",
    "    aln = alignment(env, file=fasta+'.ali' , align_codes='all' )\n",
    "    try:\n",
    "        aln.append(file=structalns[df], align_codes='all')\n",
    "        aln.salign(\n",
    "                       align_block= blockct,\n",
    "                       gap_penalties_1d=(-10, 0),\n",
    "                       gap_penalties_2d=(3.5, 3.5, 3.5, 0.2, 4.0, 6.5, 2.0, 0.0, 0.0),\n",
    "                    fit = True\n",
    "                       # d.p. score matrix\n",
    "                       #output_weights_file='salign.mtx'\n",
    "                       )\n",
    "        \"\"\"aln.write(file='align2d.pap', alignment_format='PAP',\n",
    "                  alignment_features='INDICES HELIX BETA STRAIGHTNESS ' + \\\n",
    "                                     'ACCESSIBILITY CONSERVATION')\n",
    "        \"\"\"\n",
    "        \n",
    "        #output aln\n",
    "        finalaln[df] = df+'final.ali'\n",
    "        aln.write(file=finalaln[df], alignment_format='PIR')\n",
    "        print('DONE')\n",
    "    except:\n",
    "        print('alnerr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run modeller\n",
    "print(models)\n",
    "\n",
    "# Comparative modeling by the automodel class\n",
    "from modeller import *              # Load standard Modeller classes\n",
    "from modeller.automodel import *    # Load the automodel class\n",
    "print(knowns)\n",
    "env = environ() \n",
    "env.io.atom_files_directory = ['./modellercif/', './']\n",
    "\n",
    "for df in finalaln:\n",
    "    alidf = alidfs[df]\n",
    "    print(alidf)\n",
    "    \n",
    "    print(finalaln[df])\n",
    "    for seq in alidf.index:\n",
    "        a = automodel(env,\n",
    "                      alnfile  =  finalaln[df] ,     # alignment filename\n",
    "                      knowns   =  knowns[df] ,              # codes of the templates\n",
    "                      sequence =  seq.replace('/','_')   )\n",
    "        # code of the target\n",
    "        \n",
    "        a.starting_model= 1                 # index of the first model\n",
    "        a.ending_model  = 1                 # index of the last model\n",
    "        a.repeat_optimization = 1\n",
    "        a.make()                            # do the actual comparative modeling\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run modeller\n",
    "print(models)\n",
    "\n",
    "# Comparative modeling by the automodel class\n",
    "from modeller import *              # Load standard Modeller classes\n",
    "from modeller.automodel import *    # Load the automodel class\n",
    "print(knowns)\n",
    "env = environ() \n",
    "env.io.atom_files_directory = ['./modellercif/']\n",
    "\n",
    "for df in finalaln:\n",
    "    alidf = alidfs[df]\n",
    "    print(alidf)\n",
    "    \n",
    "    first   =  knowns[df][0].split('_')[0]\n",
    "    \n",
    "    firststruct = [ s for s in knowns[df] if first in s]\n",
    "    \n",
    "    print(finalaln[df])\n",
    "    for seq in alidf.index: \n",
    "        a = automodel(env,\n",
    "                      alnfile  = finalaln[df],     # alignment filename\n",
    "                      knowns   =  firststruct ,              # codes of the templates\n",
    "                      sequence =   seq.replace('/','_')  )              # code of the target\n",
    "        a.starting_model= 1                 # index of the first model\n",
    "        a.ending_model  = 1                 # index of the last model\n",
    "        a.repeat_optimization = 2\n",
    "        a.make()                            # do the actual comparative modeling\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
